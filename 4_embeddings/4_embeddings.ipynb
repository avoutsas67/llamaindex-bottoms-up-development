{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaIndex Bottoms-Up Development - Embeddings\n",
    "Embeddings are numerical representations of text. To generate embeddings for text, a specific model is required.\n",
    "\n",
    "In LlamaIndex, the default embedding model is `text-embedding-ada-002` from OpenAI. You can also leverage any embedding models offered by Langchain and Huggingface using our `LangchainEmbedding` wrapper.\n",
    "\n",
    "In this notebook, we cover the low-level usage for both OpenAI embeddings and HuggingFace embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "OpenAI version: 1.33.0\n",
      "llamaindex version: 0.10.43\n",
      "OPENAI_API_KEY: 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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv  # type: ignore\n",
    "\n",
    "# ## Using the OpenAI LLM with the VectorStoreIndex\n",
    "from openai import __version__ as openai_version  # type: ignore\n",
    "from llama_index.core import __version__ as llama_index_version  # type: ignore\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"OpenAI version: {openai_version}\")\n",
    "print(f\"llamaindex version: {llama_index_version}\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "[-0.0077317021787166595, -0.0055575682781636715, -0.016167471185326576, -0.03340408205986023, -0.016780272126197815, -0.003158524166792631, -0.015606825239956379, -0.0019084787927567959, -0.003049328690394759, -0.026989247649908066]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "\n",
    "openai_embedding = OpenAIEmbedding()\n",
    "\n",
    "\n",
    "embed = openai_embedding.get_text_embedding(\"hello world!\")\n",
    "\n",
    "print(len(embed))\n",
    "\n",
    "\n",
    "print(embed[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Embeddings\n",
    "While we can integrate with any embeddings offered by Langchain, you can also implement the `BaseEmbedding` class and run your own custom embedding model!\n",
    "\n",
    "For this, we will use the `InstructorEmbedding` pip package, in order to run `hkunlp/instructor-large` model found here: https://huggingface.co/hkunlp/instructor-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instal dependencies\n",
    "# Requires Python 3.11\n",
    "# !pip install InstructorEmbedding torch transformers \"sentence_transformers==2.2.2\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the embeddings! Instructor embeddings work by telling it to represent text in a particular domain. \n",
    "\n",
    "This makes sense for our llama-docs-bot, since we are search very specific documentation!\n",
    "\n",
    "Let's quickly test to make sure everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voutsas\\development\\training\\llamaindex\\llamaindex-bottoms-up-development\\.venv-py311\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "[[-6.15552776e-02  1.04199853e-02  5.88440662e-03  1.93768851e-02\n",
      "   5.71417958e-02  2.57655643e-02 -4.01940270e-05 -2.80044470e-02\n",
      "  -2.92965434e-02  4.91884910e-02  6.78200126e-02  2.18692329e-02\n",
      "   4.54528593e-02  1.50187062e-02 -4.84451912e-02 -3.25259753e-02\n",
      "  -3.56492735e-02  1.19935395e-02 -6.83914730e-03  3.03126331e-02\n",
      "   5.17491698e-02  3.48140597e-02  4.91033122e-03  6.68928474e-02\n",
      "   1.52824298e-02  3.54217105e-02  1.07743675e-02  6.89828917e-02\n",
      "   4.44019437e-02 -3.23419534e-02  1.24267964e-02 -2.15528104e-02\n",
      "  -1.62690841e-02 -4.15058322e-02 -2.42290529e-03 -3.07158497e-03\n",
      "   4.27047350e-02  1.56428553e-02  2.57813167e-02  5.92843294e-02\n",
      "  -1.99174136e-02  1.32361772e-02  1.08407997e-02 -4.00610678e-02\n",
      "  -1.36213552e-03 -1.57032814e-02 -2.53812131e-02 -1.31972851e-02\n",
      "  -7.83779565e-03 -1.14009008e-02 -4.82025407e-02 -2.58416161e-02\n",
      "  -4.98770131e-03  4.98239510e-02  1.19490083e-02 -5.55060580e-02\n",
      "  -2.82120425e-02 -3.32208797e-02  2.46765073e-02 -5.66114523e-02\n",
      "  -5.12200873e-03  1.95142794e-02 -2.12629847e-02  1.92354098e-02\n",
      "   2.46065017e-02 -4.58347611e-02  3.27664390e-02 -3.99055779e-02\n",
      "   5.31269275e-02  9.05541121e-04  4.53844778e-02 -2.51501203e-02\n",
      "   1.74823473e-03 -9.64769274e-02 -9.51786246e-03 -6.47390541e-03\n",
      "   3.51561420e-02  3.58432457e-02 -5.11278473e-02  4.30903137e-02\n",
      "   4.58191670e-02  1.91871561e-02  2.38421634e-02 -1.71816312e-02\n",
      "  -1.52623355e-02  5.40182441e-02 -5.58873937e-02  4.29563150e-02\n",
      "   8.48112535e-03  7.83620123e-03 -3.27342637e-02 -1.08465431e-02\n",
      "  -7.19641196e-03 -4.37383056e-02 -1.88113526e-02  5.16907312e-02\n",
      "   4.62869182e-02 -2.63639893e-02  3.73640880e-02  1.84657890e-02\n",
      "   5.99115416e-02  1.80116374e-04 -2.35873759e-02  5.71749359e-02\n",
      "   1.20532773e-02 -3.81674655e-02 -3.55241075e-02  2.34814058e-03\n",
      "  -4.45778109e-02  9.34025459e-03  5.85195236e-03 -3.56189273e-02\n",
      "  -2.23838575e-02 -1.38210889e-03  8.74637719e-03  2.08802354e-02\n",
      "   7.03729093e-02 -4.39636931e-02 -4.53046672e-02 -4.76960428e-02\n",
      "   4.33718488e-02 -1.97183155e-03 -5.65528404e-03 -2.16748025e-02\n",
      "  -7.46926218e-02  1.90407708e-02 -2.33457386e-02 -5.68974540e-02\n",
      "  -9.49268043e-03  4.25821356e-03  3.14501184e-03  1.90789681e-02\n",
      "  -1.00614028e-02 -6.33771345e-02  4.90879044e-02  2.97248526e-03\n",
      "  -7.01222941e-02  1.71163045e-02  1.05466926e-02  8.59851763e-02\n",
      "  -5.78762218e-02 -3.88501175e-02  4.20248136e-03 -1.92795359e-02\n",
      "  -4.11053114e-02  7.98566546e-03  4.75644208e-02 -4.87977602e-02\n",
      "  -3.62159945e-02 -2.10572649e-02  4.02226895e-02 -4.74730358e-02\n",
      "  -2.78858766e-02  8.39250907e-02 -9.76029318e-03  2.62570400e-02\n",
      "  -5.60530722e-02  1.52837224e-02  1.54583901e-03  2.02960009e-03\n",
      "  -3.28001268e-02  5.76916039e-02 -7.33235478e-02 -4.00819965e-02\n",
      "  -3.98107991e-02 -3.84523608e-02 -8.67154635e-03  1.05411708e-01\n",
      "  -2.86331098e-03 -1.91161204e-02 -5.60036525e-02  9.67337098e-03\n",
      "   5.51291071e-02  2.56363396e-03 -2.94723492e-02  5.84518276e-02\n",
      "   5.15934229e-02 -1.61305803e-03 -2.19461862e-02  5.65167479e-02\n",
      "   4.74953204e-02 -2.44090538e-02 -2.66008973e-02 -5.86746586e-03\n",
      "   2.24451292e-02 -2.23604171e-03  4.56711231e-03  3.27842422e-02\n",
      "   5.26622171e-03 -2.01674439e-02 -2.33967919e-02  4.43987288e-02\n",
      "  -1.51708396e-02  7.38916686e-03  2.71087214e-02 -2.46057846e-02\n",
      "  -1.87857077e-02 -5.61460503e-04 -3.28655392e-02 -1.21782245e-02\n",
      "   1.79727562e-03 -1.50850751e-02  2.52194293e-02  1.25257857e-02\n",
      "  -2.65362702e-04  1.23138186e-02 -6.45002862e-03  1.02272682e-01\n",
      "  -2.98037641e-02  5.94182462e-02 -2.78096879e-03 -3.49573679e-02\n",
      "   3.06671802e-02  5.42211011e-02  5.95246367e-02  4.14741337e-02\n",
      "  -4.06689616e-03 -3.94712426e-02  1.96131393e-02  5.96131235e-02\n",
      "   4.44265716e-02  4.40844074e-02 -5.12231477e-02 -3.00020445e-02\n",
      "   3.01150139e-02  2.40173992e-02 -3.39305811e-02 -1.70433875e-02\n",
      "   8.32552556e-03  2.66083330e-02  7.67713878e-03  1.76458489e-02\n",
      "  -2.06325599e-03  1.77012999e-02 -6.08421750e-02 -7.96776637e-02\n",
      "   4.99934293e-02  2.96638496e-02 -4.47008573e-03  1.65794417e-02\n",
      "  -2.35370491e-02 -3.23977787e-03  2.61382628e-02 -1.34953409e-02\n",
      "  -1.60201807e-02 -1.08793741e-02 -1.77004989e-02 -6.53112028e-03\n",
      "   6.91720024e-02 -4.63659801e-02  4.15586643e-02  1.24583682e-02\n",
      "  -1.88720762e-04  2.47693472e-02 -3.62277217e-02  5.47523722e-02\n",
      "   1.54009983e-01  6.00456353e-03 -2.70665511e-02  4.70894724e-02\n",
      "   4.09195647e-02  4.31693904e-02  6.22434281e-02 -2.51828600e-02\n",
      "   6.71826899e-02  1.89108979e-02  3.67507897e-02  7.62735680e-02\n",
      "   5.01048518e-04 -7.33285071e-03  1.95556302e-02  8.43793601e-02\n",
      "   1.24929082e-02 -2.75657303e-03  4.97817136e-02 -1.73069611e-02\n",
      "   2.77005136e-02 -2.63486262e-02 -2.21686829e-02  3.95561522e-03\n",
      "  -9.68611613e-03  3.96470688e-02 -8.72507226e-03 -1.07546085e-02\n",
      "  -2.70988904e-02 -1.17305377e-02 -1.16983969e-02  4.52318527e-02\n",
      "  -9.12858546e-03 -1.14591643e-02  8.29536002e-03 -3.94435301e-02\n",
      "   8.80731735e-03 -3.67274545e-02 -4.45834622e-02 -2.38478407e-02\n",
      "   1.73519533e-02  2.46788301e-02 -9.24503356e-02  3.40846949e-03\n",
      "  -8.58144388e-02 -1.69283785e-02  8.74705426e-03 -2.66723637e-03\n",
      "  -3.10086994e-03 -6.62742853e-02  1.74709763e-02 -6.20296821e-02\n",
      "  -7.71831870e-02 -4.30789776e-02 -6.97872937e-02 -2.76594106e-02\n",
      "  -7.36039504e-02  2.61303820e-02  4.94785495e-02  1.88994538e-02\n",
      "   2.05077361e-02  5.93992881e-03 -2.71200538e-02 -4.64439578e-02\n",
      "   2.66322903e-02  2.63824444e-02  3.03617027e-03 -4.70094755e-02\n",
      "  -8.68524704e-03 -1.94979785e-03 -1.47214374e-02 -3.10322680e-02\n",
      "  -3.54932994e-02  7.64071792e-02  9.24097896e-02  1.11720357e-02\n",
      "   6.86150696e-03  2.67613642e-02 -4.66881320e-02 -4.80801016e-02\n",
      "  -1.76523291e-02 -5.05446754e-02 -2.54300386e-02 -2.59506609e-02\n",
      "  -2.86576133e-02 -3.34676690e-02 -3.07256356e-02  6.79466315e-03\n",
      "  -5.43393157e-02 -2.23255064e-03  1.03655048e-02  3.52348424e-02\n",
      "   2.40201596e-02 -2.09922437e-03 -8.59064832e-02 -4.86475825e-02\n",
      "   3.41627002e-02  9.51632578e-03  2.42883083e-03 -6.15580939e-02\n",
      "  -2.23672669e-02  1.49234412e-02 -6.16901927e-03 -2.94565614e-02\n",
      "  -8.48871469e-03  3.98517400e-02  3.54111381e-02 -1.31471418e-02\n",
      "  -2.31656004e-02 -2.86290552e-02  1.44813089e-02 -3.19011300e-03\n",
      "   5.59895067e-03 -6.02383465e-02 -5.41782752e-02  6.31063757e-03\n",
      "  -3.27197323e-03  6.00864477e-02 -4.93385307e-02 -1.23744868e-02\n",
      "  -2.60731559e-02  3.88635322e-02  3.19503024e-02  2.37053186e-02\n",
      "  -2.05829646e-02  1.42387645e-02 -3.58667336e-02 -3.98508795e-02\n",
      "   8.55067465e-03 -2.32857801e-02  1.41011160e-02  5.81302606e-02\n",
      "  -4.17654635e-03  7.78259663e-03  8.50560814e-02  2.76554506e-02\n",
      "   4.23116237e-02  2.45192759e-02 -2.62568854e-02  3.76733430e-02\n",
      "  -1.03408834e-02  2.60650199e-02  6.19983254e-03 -1.73711050e-02\n",
      "  -5.55875376e-02 -1.02811217e-01 -8.27026460e-03 -6.74285181e-03\n",
      "  -5.95137440e-02  1.29434997e-02  4.41100970e-02 -7.02070072e-03\n",
      "  -3.03075369e-02 -9.03240312e-03  2.10526511e-02  2.01296695e-02\n",
      "  -3.11780139e-03  4.94987480e-02 -2.36510094e-02  2.80551668e-02\n",
      "  -2.48605181e-02  5.25816390e-03 -5.47549501e-02 -1.80020761e-02\n",
      "  -6.72238413e-03  7.68097267e-02  2.41172519e-02  6.28411695e-02\n",
      "   4.77913283e-02 -1.15464898e-02 -4.14417088e-02  2.10504960e-02\n",
      "   6.09488524e-02 -2.36858111e-02 -3.18970978e-02  2.34901626e-03\n",
      "  -2.75847316e-03  1.48618000e-03 -4.22430644e-03  5.57199260e-03\n",
      "   2.00943612e-02  5.29720709e-02 -3.99871245e-02 -1.41997505e-02\n",
      "   3.94999646e-02 -1.47230811e-02 -4.10683779e-03 -6.41633645e-02\n",
      "  -2.31138486e-02  1.63525809e-03  6.87346607e-03  5.51297851e-02\n",
      "   1.13907289e-02  3.55854817e-02  5.87924384e-02  2.42435914e-02\n",
      "  -3.97643819e-02 -7.16551840e-02  4.69529629e-02 -3.05532129e-03\n",
      "  -4.91016544e-02 -9.50928181e-02 -1.41104115e-02  2.90551018e-02\n",
      "   2.07553748e-02 -2.56224140e-03 -2.63764709e-02 -5.93052851e-03\n",
      "   6.81197867e-02 -2.53772419e-02  6.08022772e-02  4.24165577e-02\n",
      "   4.66698818e-02  3.79461423e-02 -1.22388788e-02  6.11324459e-02\n",
      "  -1.82264969e-02 -8.81061889e-03  2.42136922e-02  2.62034386e-02\n",
      "  -1.55039085e-02 -2.20747180e-02 -5.16002961e-02  2.53373291e-02\n",
      "   3.05230375e-02  1.20210275e-02  8.25989917e-02 -2.68187299e-02\n",
      "  -3.36164050e-02 -3.96278389e-02  2.64574606e-02 -4.73223366e-02\n",
      "   5.45928292e-02  4.71893139e-02  5.40369861e-02 -3.63412127e-02\n",
      "  -4.38812040e-02 -9.25776176e-03 -1.49381887e-02  1.94572564e-02\n",
      "  -4.68942896e-02 -2.96848826e-02 -6.92514852e-02  2.51878537e-02\n",
      "  -1.31794084e-02 -3.26385349e-02 -8.38335454e-02  1.62501168e-02\n",
      "   5.05867740e-03 -3.85647677e-02  4.18353155e-02  4.50653583e-02\n",
      "   4.53344658e-02  3.85494530e-02  5.27763143e-02  9.01089981e-03\n",
      "  -2.32415237e-02  4.14123312e-02 -3.90885323e-02 -1.84995309e-02\n",
      "  -2.91617345e-02 -6.02056943e-02 -3.62730995e-02  4.92623774e-03\n",
      "  -1.51348123e-02 -1.77912693e-02 -6.56069582e-03  3.74852866e-02\n",
      "  -4.98751411e-03  3.45563255e-02  8.38177837e-03  1.23971272e-02\n",
      "   1.30274547e-02 -5.76015376e-02 -1.41846286e-02 -3.29240151e-02\n",
      "  -6.02640510e-02 -4.08707112e-02  6.09732494e-02 -5.65142836e-03\n",
      "  -2.64281482e-02  1.45490011e-02  1.39951417e-02  2.01470479e-02\n",
      "   1.63883865e-02 -4.30175997e-02  8.81800707e-03  9.79693513e-03\n",
      "  -4.37083356e-02 -1.07098548e-02 -2.09241938e-02 -1.68447625e-02\n",
      "   2.54024155e-02 -4.39964272e-02  2.77971886e-02  2.39688382e-02\n",
      "   4.46380675e-03 -4.09839526e-02  1.39753679e-02 -1.02954349e-02\n",
      "  -4.48161736e-02  1.04085505e-02 -2.32339501e-02  8.22256692e-03\n",
      "   1.08464006e-02 -7.12043094e-03 -2.48804055e-02  1.47036724e-02\n",
      "  -1.03130303e-02  5.29496670e-02  2.34216210e-02 -3.16518135e-02\n",
      "   2.24910639e-02 -1.01565300e-02  2.24805437e-02 -6.64025098e-02\n",
      "   2.63604466e-02 -2.33393162e-02  2.29447111e-02 -1.88058522e-02\n",
      "  -2.10312125e-03 -4.88403328e-02  4.41654585e-02 -2.42530424e-02\n",
      "  -3.33837755e-02  6.30348222e-03  1.08949444e-03  1.65918039e-03\n",
      "   1.43814655e-02 -6.16017962e-03  2.33820472e-02 -6.41303733e-02\n",
      "   2.14748476e-02  1.68789215e-02 -1.88098792e-02 -1.45088285e-02\n",
      "   4.35655713e-02 -3.56806591e-02 -1.71170756e-02  4.00119089e-03\n",
      "  -1.24642039e-02  3.74952108e-02  3.54862548e-02  2.71979510e-03\n",
      "   4.88897339e-02 -1.42481448e-02 -2.37889662e-02  1.45645402e-02\n",
      "  -5.29264621e-02 -3.16047631e-02 -2.55868006e-02  6.24954642e-04\n",
      "   1.23044671e-02  1.52396709e-02  5.92730567e-03 -6.96792603e-02\n",
      "  -4.38257121e-02  3.32457684e-02  4.29933220e-02  3.41573507e-02\n",
      "   5.74664399e-03  6.92842109e-03  2.19891742e-02  5.40519990e-02\n",
      "  -3.47650945e-02 -6.38605328e-03 -1.06168529e-02  5.59755974e-03\n",
      "   2.51517370e-02  1.97777199e-03 -9.76093952e-03  1.29118161e-02\n",
      "  -5.10915853e-02 -4.22592610e-02  6.32157102e-02  6.68454021e-02\n",
      "   3.72742862e-02 -1.31203597e-02 -3.29279862e-02  3.23108919e-02\n",
      "   2.64140945e-02 -4.51177210e-02  6.29258156e-02 -3.71045782e-03\n",
      "  -3.95429470e-02  5.86496852e-02 -5.98639343e-03  1.91448182e-02\n",
      "   3.20215262e-02  5.33388555e-02 -2.62014288e-02  2.29458008e-02\n",
      "  -1.26508726e-02  6.65134657e-03  6.07207865e-02 -3.29924598e-02\n",
      "  -2.04965323e-02 -5.14310226e-02  6.54849932e-02 -4.22492214e-02\n",
      "   9.26519334e-02  1.99730117e-02 -1.83647871e-02  1.88231340e-03\n",
      "  -4.16838489e-02 -6.10365607e-02  2.76884995e-02 -3.12236175e-02\n",
      "   5.57781421e-02 -3.40828039e-02 -5.36403544e-02  3.83231491e-02\n",
      "   1.50124626e-02 -6.74923286e-02  6.30307645e-02  1.23501047e-02\n",
      "   5.98304160e-02  2.07509436e-02  3.15652192e-02 -3.75223570e-02\n",
      "   3.68294008e-02 -6.04589507e-02  9.98122338e-03 -3.74645405e-02\n",
      "   4.14429558e-03  2.01168358e-02 -1.38435969e-02 -6.81752106e-03\n",
      "   3.87795176e-03 -8.58291984e-03 -1.53929344e-03  4.07204069e-02\n",
      "  -5.60819432e-02 -6.66264743e-02  2.24500243e-02  1.80751812e-02\n",
      "  -1.88873673e-03  1.47162750e-02 -2.16904860e-02  8.98237433e-03\n",
      "   3.33474651e-02 -1.17769381e-02 -2.53784508e-02  7.49978749e-03\n",
      "   1.59923322e-02 -5.08552380e-02 -2.55495608e-02  3.99981141e-02\n",
      "   2.41954252e-03 -1.39974169e-02  1.12951547e-02  1.01209746e-03\n",
      "  -1.35132068e-04  1.50756836e-02  3.66246398e-03  3.56586315e-02\n",
      "  -2.39739623e-02 -5.98191749e-03 -1.14465076e-02  7.17897667e-03\n",
      "  -7.58273154e-03 -1.56441089e-02  2.08631828e-02  4.67960909e-02\n",
      "   9.20427963e-03  9.97736771e-03 -1.69361904e-02 -3.79866660e-02\n",
      "   2.12063938e-02 -3.93209755e-02  2.39590108e-02  4.52189846e-03\n",
      "  -4.90421988e-02 -2.53686700e-02 -5.13280481e-02 -3.11175790e-02\n",
      "   3.69731225e-02 -3.32236476e-02  2.64319703e-02  3.13280337e-02\n",
      "   5.02048098e-02 -3.51830274e-02 -9.47780088e-02 -3.81823666e-02\n",
      "  -2.52812915e-02  8.34160671e-03  1.06830746e-02 -2.85213124e-02\n",
      "   1.14974417e-02 -1.63908284e-02 -5.35691418e-02  1.44921439e-02\n",
      "   1.44734317e-02  1.46977548e-02  3.46375890e-02  4.89880666e-02\n",
      "  -2.99605597e-02  7.35144271e-03  1.49103850e-02 -2.81755906e-02\n",
      "   4.02826704e-02  1.23249069e-02  2.03392226e-02  4.75965291e-02\n",
      "   4.34238613e-02  8.02048575e-03 -1.76124298e-03 -6.28188998e-02\n",
      "  -4.67858873e-02 -3.76613960e-02  1.02270348e-02  4.39473838e-02]]\n"
     ]
    }
   ],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "model = INSTRUCTOR(\"hkunlp/instructor-large\")\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Science title:\"\n",
    "embeddings = model.encode([[instruction, sentence]])\n",
    "print(embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! But we can see the output is batched (i.e. a list of lists), so we need to undo the batching in our implementation!\n",
    "\n",
    "There are only 4 methods we need to implement below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.instructor import InstructorEmbedding\n",
    "\n",
    "embed_model = InstructorEmbedding(model_name=\"hkunlp/instructor-base\")\n",
    "embeddings = embed_model.get_text_embedding(\"Hello World!\")\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\voutsas\\development\\training\\llamaindex\\llamaindex-bottoms-up-development\\.venv-py311\\Lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, List\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "\n",
    "from llama_index.core.bridge.pydantic import PrivateAttr\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "\n",
    "\n",
    "class InstructorEmbeddings(BaseEmbedding):\n",
    "    _model: INSTRUCTOR = PrivateAttr()\n",
    "    _instruction: str = PrivateAttr()\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        instructor_model_name: str = \"hkunlp/instructor-large\",\n",
    "        instruction: str = \"Represent a document for semantic search:\",\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        self._model = INSTRUCTOR(instructor_model_name)\n",
    "        self._instruction = instruction\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"instructor\"\n",
    "\n",
    "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        embeddings = self._model.encode([[self._instruction, query]])\n",
    "        return embeddings[0]\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        embeddings = self._model.encode([[self._instruction, text]])\n",
    "        return embeddings[0]\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        embeddings = self._model.encode([[self._instruction, text] for text in texts])\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# set the batch size to 1 to avoid memory issues\n",
    "# if you have a large GPU, you can increase this\n",
    "instructor_embeddings = InstructorEmbeddings(embed_batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "[ 0.0122677   0.01026734 -0.00182734  0.00379927 -0.00021093  0.04484274\n",
      "  0.00842185  0.01182631 -0.03821287  0.01453499]\n"
     ]
    }
   ],
   "source": [
    "embed = instructor_embeddings._get_text_embedding(\"How do I create a vector index?\")\n",
    "print(len(embed))\n",
    "print(embed[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Embeddings w/ LlamaIndex\n",
    "\n",
    "Since Instructor embeddings have a max length of 512, we set the chunk size to 512 as well.\n",
    "\n",
    "However, if the emebddings are longer, there will not be an error, but only the first 512 tokens will be captured!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voutsas\\AppData\\Local\\Temp\\ipykernel_22240\\1394086211.py:5: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import ServiceContext, set_global_service_context\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=instructor_embeddings, chunk_size=512\n",
    ")\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SimpleDirectoryReader' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_docs_bot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_query_engine\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# remove any existing indices\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# !rm -rf ./*_index\u001b[39;00m\n\u001b[0;32m     11\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m create_query_engine()\n",
      "File \u001b[1;32mc:\\Users\\voutsas\\development\\training\\llamaindex\\llamaindex-bottoms-up-development\\4_embeddings\\..\\llama_docs_bot\\indexing.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnest_asyncio\u001b[39;00m \u001b[38;5;66;03m#type:ignore\u001b[39;00m\n\u001b[0;32m      3\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarkdown_docs_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkdownDocsReader\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     SimpleDirectoryReader, \n\u001b[0;32m      8\u001b[0m     VectorStoreIndex,\n\u001b[0;32m      9\u001b[0m     StorageContext, \n\u001b[0;32m     10\u001b[0m     load_index_from_storage\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrieverQueryEngine\n",
      "File \u001b[1;32mc:\\Users\\voutsas\\development\\training\\llamaindex\\llamaindex-bottoms-up-development\\4_embeddings\\..\\llama_docs_bot\\markdown_docs_reader.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, cast\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseReader\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document, NodeRelationship, RelatedNodeInfo\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SimpleDirectoryReader' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "from llama_docs_bot.indexing import create_query_engine\n",
    "\n",
    "# remove any existing indices\n",
    "# !rm -rf ./*_index\n",
    "\n",
    "query_engine = create_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query('What is the Sub Question query engine?')\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.get_formatted_sources(length=256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to default embeddings\n",
    "\n",
    "Note that an index must be using the same embedding model at query time that was used to create the index.\n",
    "\n",
    "So below, we delete the existing indicies and rebuild them using OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=OpenAIEmbedding(), chunk_size=512)\n",
    "set_global_service_context(service_context)\n",
    "\n",
    "# delete old vector index so we can re-create it\n",
    "!rm -rf ./*_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = create_query_engine()\n",
    "\n",
    "response = query_engine.query('What is the Sub Question query engine?')\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.get_formatted_sources(length=256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we showed how to use the low-level embeddings, as well as how to create your own embeddings class.\n",
    "\n",
    "If you wanted to use these embeddings in your project (which we will be doing in future guides!), you can use the sample example below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
